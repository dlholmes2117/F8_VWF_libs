{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6c59f4-9cb2-40d6-b1f7-c4a0a18367fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "from scipy.spatial import distance\n",
    "import json\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "import random\n",
    "import pprint\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c95b2d3f-69ca-451d-874b-d007c0cca97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAAA</th>\n",
       "      <th>AAAC</th>\n",
       "      <th>AAAG</th>\n",
       "      <th>AAAT</th>\n",
       "      <th>AACA</th>\n",
       "      <th>AACC</th>\n",
       "      <th>AACG</th>\n",
       "      <th>AACT</th>\n",
       "      <th>AAGA</th>\n",
       "      <th>AAGC</th>\n",
       "      <th>...</th>\n",
       "      <th>TTCG</th>\n",
       "      <th>TTCT</th>\n",
       "      <th>TTGA</th>\n",
       "      <th>TTGC</th>\n",
       "      <th>TTGG</th>\n",
       "      <th>TTGT</th>\n",
       "      <th>TTTA</th>\n",
       "      <th>TTTC</th>\n",
       "      <th>TTTG</th>\n",
       "      <th>TTTT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overhang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TTTT</th>\n",
       "      <td>636</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTTT</th>\n",
       "      <td>4</td>\n",
       "      <td>477</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTTT</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>597</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATTT</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>643</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGTT</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>494</td>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACAA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAAA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>362</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAAA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>716</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAAA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AAAA  AAAC  AAAG  AAAT  AACA  AACC  AACG  AACT  AAGA  AAGC  ...  \\\n",
       "Overhang                                                              ...   \n",
       "TTTT       636     9    41    17     3     1     1     1     8     1  ...   \n",
       "GTTT         4   477     5    46     1    21     1     2     1    16  ...   \n",
       "CTTT         2     2   597     3     1     1    19     1     1     1  ...   \n",
       "ATTT         9     5     2   643     1     1     1     7     1     2  ...   \n",
       "TGTT         1     1     1     1   494    17    65    57     3     1  ...   \n",
       "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "ACAA         1     1     1     1     1     1     1     1     1     1  ...   \n",
       "TAAA         1     1     1     1     1     1     1     1     1     1  ...   \n",
       "GAAA         1     1     1     1     1     1     1     1     1     1  ...   \n",
       "CAAA         1     1     1     1     1     1     1     1     1     1  ...   \n",
       "AAAA         1     1     1     1     1     1     1     1     1     1  ...   \n",
       "\n",
       "          TTCG  TTCT  TTGA  TTGC  TTGG  TTGT  TTTA  TTTC  TTTG  TTTT  \n",
       "Overhang                                                              \n",
       "TTTT         1     1     1     1     1     1     1     1     1     1  \n",
       "GTTT         1     1     1     1     1     1     1     1     1     1  \n",
       "CTTT         1     1     1     1     1     1     1     1     1     1  \n",
       "ATTT         1     1     1     1     1     1     1     1     1     1  \n",
       "TGTT         1     1     1     1     1     1     1     1     1     1  \n",
       "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "ACAA         1     1    11     3     8   480     1     1     1     1  \n",
       "TAAA         1     1     1     1     1     1   362     1    11     4  \n",
       "GAAA         1     1     1     3     1     1     6   716     2    20  \n",
       "CAAA         5     1     1     1     1     1     4     1   486     1  \n",
       "AAAA         1     1     1     1     1     1     5     4     2   636  \n",
       "\n",
       "[256 rows x 256 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import BsaI data\n",
    "bsaI_empirical = pd.read_csv('../bsaI_empirical.csv')\n",
    "bsaI_empirical.index = bsaI_empirical['Overhang']\n",
    "bsaI_empirical = bsaI_empirical.drop(columns=['Overhang'])\n",
    "bsaI_empirical = bsaI_empirical + 1\n",
    "bsaI_empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "669e2aea-3c5d-4952-8a08-62a716d10ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AATT',\n",
       " 'ACGT',\n",
       " 'AGCT',\n",
       " 'ATAT',\n",
       " 'GTTG',\n",
       " 'GGTG',\n",
       " 'CATG',\n",
       " 'GTGG',\n",
       " 'GGGG',\n",
       " 'GCGG',\n",
       " 'CCGG',\n",
       " 'GGCG',\n",
       " 'CGCG',\n",
       " 'CTAG',\n",
       " 'GATC',\n",
       " 'GCGC',\n",
       " 'CCGC',\n",
       " 'GGCC',\n",
       " 'CGCC',\n",
       " 'CCCC',\n",
       " 'CACC',\n",
       " 'GTAC',\n",
       " 'CCAC',\n",
       " 'CAAC',\n",
       " 'TATA',\n",
       " 'TCGA',\n",
       " 'TGCA',\n",
       " 'TTAA']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set blacklist of inefficient or nonspecific codons (DH updated 20250501)\n",
    "overhang_blacklist = []\n",
    "\n",
    "for codon in bsaI_empirical.index:\n",
    "    # make sure we're working with plain strings\n",
    "    codon_str = str(codon)\n",
    "    rc_str    = str(Seq(codon_str).reverse_complement())\n",
    "\n",
    "    # first, drop any palindromic (self-complementary) codons\n",
    "    if codon_str == rc_str:\n",
    "        overhang_blacklist.append(codon_str)\n",
    "        continue\n",
    "\n",
    "    # then test your efficiency threshold, but only if that rc exists as a column\n",
    "    if rc_str in bsaI_empirical.columns:\n",
    "        eff = bsaI_empirical.loc[codon_str, rc_str]\n",
    "        if eff < 300:\n",
    "            overhang_blacklist.append(codon_str)\n",
    "    else:\n",
    "        # optionally warn if you have no measurement for that pair\n",
    "        print(f\"Warning: no data for {codon_str} → {rc_str}\")\n",
    "\n",
    "overhang_blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92b8bba-f031-4dfe-946a-0b0603cc3bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is checking for non-specific binding of primers, it outputs a list of WT fragments that each priemr anneals to incorrectly\n",
    "def post_qc(amp_primer_set, wt_oligos, primer_set, melt_temp_threshold = 35, check_all_primers=True):\n",
    "    print(\"Running QC for primer specificity on WT oligos\")\n",
    "    f_primer_map = {}\n",
    "    r_primer_map = {}\n",
    "    # invert the primer to subpool map\n",
    "    for k, v in amp_primer_set.items():\n",
    "        f_primer_map[v[1]] = f_primer_map.get(v[1], []) + [k]\n",
    "        r_primer_map[v[3]] = r_primer_map.get(v[3], []) + [k]\n",
    "    \n",
    "    # initialize list of nonspecific problems\n",
    "    nonspecific = {}\n",
    "    \n",
    "    # add unused primers if check_all_primers\n",
    "    if check_all_primers:\n",
    "        all_f_primers = np.unique(primer_set['Forward Primer'])\n",
    "        all_r_primers = np.unique(primer_set['Reverse Primer'])\n",
    "        for f_primer in all_f_primers:\n",
    "            if f_primer not in f_primer_map.keys():\n",
    "                f_primer_map[f_primer] = []\n",
    "        for r_primer in all_r_primers:\n",
    "            if r_primer not in r_primer_map.keys():\n",
    "                r_primer_map[r_primer] = []\n",
    "        \n",
    "    for f_primer, subpools_used in f_primer_map.items():\n",
    "    # iterate over every barcode primer pair and match to each oligo to check for nonspecific amplification\n",
    "        anneal_locs = []\n",
    "        for subpoolcheck, fragmentcheck in wt_oligos.items():  # iterate over every WT oligo\n",
    "            if (subpoolcheck not in subpools_used):  # ignore designed annealing (same name)\n",
    "                if check_nonspecific(f_primer, fragmentcheck, Tm_rem = melt_temp_threshold, verbose=False) > 0: #use high Tm_rem\n",
    "                    anneal_locs.append(subpoolcheck)\n",
    "        if anneal_locs:\n",
    "            nonspecific.update({f_primer:[a[0] + '_block' + str(a[1]+1) for a in anneal_locs]})\n",
    "    for r_primer, subpools_used in r_primer_map.items():\n",
    "    # iterate over every barcode primer pair and match to each oligo to check for nonspecific amplification\n",
    "        anneal_locs = []\n",
    "        for subpoolcheck, fragmentcheck in wt_oligos.items():  # iterate over every WT oligo\n",
    "            if (subpoolcheck not in subpools_used):  # ignore designed annealing (same name)\n",
    "                if check_nonspecific(r_primer, fragmentcheck, Tm_rem = melt_temp_threshold, verbose=False) > 0: #use high Tm_rem\n",
    "                    anneal_locs.append(subpoolcheck)\n",
    "        if anneal_locs:\n",
    "            nonspecific.update({r_primer:[a[0] + '_block' + str(a[1]+1) for a in anneal_locs]})\n",
    "    if nonspecific:\n",
    "        print(\"Nonspecific Primers: (Manually removing primer sequence recommended)\")\n",
    "        print(nonspecific)\n",
    "    else:\n",
    "        print(\"No non-specific primers detected\")\n",
    "        \n",
    "    return nonspecific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc39308-2b4e-42d7-85c1-01d4b4a56864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is taking in each sequence and returning a list of contiguous sequences of length ksize from each sequence\n",
    "def build_kmers(sequence, \n",
    "                ksize):\n",
    "    kmers = []\n",
    "    n_kmers = len(sequence) - ksize + 1\n",
    "\n",
    "    for i in range(n_kmers):\n",
    "        kmer = sequence[i:i + ksize]\n",
    "        kmers.append(kmer)\n",
    "\n",
    "    return kmers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "185f7eda-c33c-4cec-b48e-d0b16ed595eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is taking a sequence (gene), positions of breakpoints for where the gene should be broken up,\n",
    "# and an inclusion array that tells how adjacent blocks should be connected. \n",
    "# Step1: builds the overlaps by taking the breakpoint positions and defining the left edge and right\n",
    "# edge of each junction\n",
    "# Step2: walks through the inclusion array and... I'll come back to this one\n",
    "def compute_overlaps(breakpoints, \n",
    "                     inclusion_array, \n",
    "                     gene):\n",
    "    \n",
    "    overlaps = [[gene[val:val+4].reverse_complement(), gene[val:val+4]] for val in breakpoints]\n",
    "    counter = 0\n",
    "    for val in inclusion_array:\n",
    "        if val == -1:\n",
    "            (overlaps[counter][1],overlaps[counter+1][0]) = (overlaps[counter+1][0],overlaps[counter][1])\n",
    "            counter += 1\n",
    "        elif val == 0:\n",
    "            overlaps[counter][1] = overlaps[counter+1][1]\n",
    "            del overlaps[counter+1]\n",
    "        \n",
    "    return overlaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74e386f6-58e7-4ab9-bb8d-7ab5f9255b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a sequence (gene), a breakpoint pair, the emperical GGA overlap dataframe (emperical), and the \n",
    "# black list of overhangs that aren't allowed to compute a fidelity score for each possible breakpoint based\n",
    "# on the NEB data\n",
    "# Step1: collect all overlaps and their RCs\n",
    "# Step2: make sure the overhangs are unique and none are in the blacklist\n",
    "# Step3: subset the NEB matrix to just the overhangs being used\n",
    "# Step4: row-normalize to convert the counts to probabilities\n",
    "# Step5: compute the fidelity\n",
    "def score_breakpoints(gene, \n",
    "                      breakpoint_pair, \n",
    "                      empirical, \n",
    "                      overhang_blacklist=overhang_blacklist):\n",
    "    \n",
    "    #subset empirical matrix by the set of all overlaps\n",
    "    all_overlaps = []\n",
    "    for breakpoint in breakpoint_pair:\n",
    "        all_overlaps.append(gene[breakpoint:(breakpoint+4)])\n",
    "        all_overlaps.append(gene[breakpoint:(breakpoint+4)].reverse_complement())\n",
    "    all_overlaps = [str(o) for o in all_overlaps]\n",
    "    if (len(np.unique(all_overlaps)) == len(all_overlaps)) & (len(set(all_overlaps).intersection(set(overhang_blacklist))) == 0):\n",
    "        empirical_subset = empirical.loc[all_overlaps,all_overlaps]\n",
    "\n",
    "        #compute fidelity score\n",
    "        empirical_subset = empirical_subset/empirical_subset.sum(axis=1)\n",
    "        fidelity_score = 1\n",
    "        for breakpoint in breakpoint_pair:\n",
    "            fidelity_score = fidelity_score * empirical_subset.loc[gene[breakpoint:(breakpoint+4)],gene[breakpoint:(breakpoint+4)].reverse_complement()]\n",
    "    \n",
    "    else:\n",
    "        fidelity_score = 0\n",
    "    \n",
    "    return fidelity_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0da78475-62b7-437d-b638-1bba004635e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a gene and breakpoint pair and does a local search around the breakpoints within a slack window\n",
    "# to find the shifts that maximize ligation fidelity. It returns the best breakpoints, the best score, and a length\n",
    "# metric between two reference indicies\n",
    "def optimize_breakpoints(gene, \n",
    "                         breakpoint_pair, \n",
    "                         indices_to_shift, \n",
    "                         indices_of_array,\n",
    "                         slack, \n",
    "                         empirical=bsaI_empirical, \n",
    "                         overhang_blacklist=overhang_blacklist):\n",
    "    \n",
    "    #compute all enrichments\n",
    "    shifts = list(range(-slack,slack+1))\n",
    "    if (len(indices_to_shift) > 2) | (len(indices_to_shift) < 1):\n",
    "        print('Error -- too many or too few breakpoints!')\n",
    "        optimum_breakpoint = breakpoint_pair\n",
    "        optimum_score = 0\n",
    "    elif (len(indices_to_shift) == 1): #external pair\n",
    "        scores = [0]*len(shifts)\n",
    "        for i,shift in enumerate(shifts):\n",
    "            scores[i] = score_breakpoints(gene, breakpoint_pair[0:indices_to_shift[0]] + [breakpoint_pair[indices_to_shift[0]]+shift] + breakpoint_pair[(indices_to_shift[0]+1):], \n",
    "                                          empirical=bsaI_empirical, overhang_blacklist=overhang_blacklist)\n",
    "        \n",
    "        optimum_shift = np.argmax(scores)\n",
    "        optimum_breakpoint = breakpoint_pair[0:indices_to_shift[0]] + [breakpoint_pair[indices_to_shift[0]]+shifts[optimum_shift]] + breakpoint_pair[(indices_to_shift[0]+1):]\n",
    "        optimum_score = scores[optimum_shift]\n",
    "        optimum_length = optimum_breakpoint[indices_of_array[1]] - optimum_breakpoint[indices_of_array[0]]\n",
    "            \n",
    "            \n",
    "    else: #internal pair\n",
    "        indices_to_shift = sorted(indices_to_shift)\n",
    "        scores = np.zeros((len(shifts),len(shifts)))\n",
    "        for i,shift1 in enumerate(shifts):\n",
    "            for j,shift2 in enumerate(shifts):\n",
    "                scores[i,j] = score_breakpoints(gene, breakpoint_pair[0:indices_to_shift[0]] + [breakpoint_pair[indices_to_shift[0]]+shift1] + \\\n",
    "                                                            breakpoint_pair[(indices_to_shift[0]+1):indices_to_shift[1]] + \\\n",
    "                                                            [breakpoint_pair[indices_to_shift[1]]+shift2] + breakpoint_pair[(indices_to_shift[1]+1):], \n",
    "                                              empirical=bsaI_empirical, overhang_blacklist=overhang_blacklist)\n",
    "                \n",
    "        optimum_shift = np.unravel_index(np.argmax(scores,axis=None), scores.shape)\n",
    "        optimum_breakpoint = breakpoint_pair[0:indices_to_shift[0]] + [breakpoint_pair[indices_to_shift[0]]+shifts[optimum_shift[0]]] + \\\n",
    "                                            breakpoint_pair[(indices_to_shift[0]+1):indices_to_shift[1]] + \\\n",
    "                                            [breakpoint_pair[indices_to_shift[1]]+shifts[optimum_shift[1]]] + breakpoint_pair[(indices_to_shift[1]+1):]\n",
    "        optimum_score = scores[optimum_shift]\n",
    "        optimum_length = optimum_breakpoint[indices_of_array[1]] - optimum_breakpoint[indices_of_array[0]] + 4\n",
    "    \n",
    "    return optimum_breakpoint, optimum_score, optimum_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fde1d8e-31e4-44ea-82ff-e67faa33131c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'block_size_range' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This splits a coding sequence into a set of blocks and tiles with 4bp overhangs then optimizes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# the breakpoint positions while keeping each tile under a certain length\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Step1: Takes the length of each gene and size of its encoded protein and rejects anyhting with a length over\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#         optimum_lengths,      per-tile lengths\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#         oligo_array_indices)  per-tile [start_idx, end_idx] used for length calc\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize_gene\u001b[39m(gene, \n\u001b[1;32m     20\u001b[0m                   max_tile_size,\n\u001b[1;32m     21\u001b[0m                   first_last_block_reduction,\n\u001b[0;32m---> 22\u001b[0m                   block_size_range\u001b[38;5;241m=\u001b[39mblock_size_range, \n\u001b[1;32m     23\u001b[0m                   slack\u001b[38;5;241m=\u001b[39mslack, \n\u001b[1;32m     24\u001b[0m                   empirical\u001b[38;5;241m=\u001b[39mbsaI_empirical, \n\u001b[1;32m     25\u001b[0m                   overhang_blacklist\u001b[38;5;241m=\u001b[39moverhang_blacklist): \n\u001b[1;32m     26\u001b[0m     \n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m#setup initial inputs to optimization\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     gene_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(gene)\n\u001b[1;32m     29\u001b[0m     protein_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(gene\u001b[38;5;241m.\u001b[39mtranslate())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'block_size_range' is not defined"
     ]
    }
   ],
   "source": [
    "# This splits a coding sequence into a set of blocks and tiles with 4bp overhangs then optimizes\n",
    "# the breakpoint positions while keeping each tile under a certain length\n",
    "# Step1: Takes the length of each gene and size of its encoded protein and rejects anyhting with a length over\n",
    "# 620aas\n",
    "# Step2: Chooses a nominal block size from a given range that makes the number of tiles as close to an integer\n",
    "# as possible when tiling a padded length (padding is shrinking the first and last tiles later,\n",
    "# while making the interior tiles uniform\n",
    "# Step3: Grows the number of tiles until every tile fits the size cap, then makes the breakpoint sets per tile.\n",
    "# Step4: optimize each tile's breakpoints locally. For every breakpoint array you shift one internal breakpoint\n",
    "# for first/last tiles or two breakpoints for internal tiles\n",
    "# each call returns the optimum breakpoint, optimum score, and the optimum length\n",
    "# Step5: summarizes the overlaps and fidelity\n",
    "# Step6: returns:\n",
    "# (optimum_breakpoints,  list per tile of optimized breakpoint arrays\n",
    "#         optimum_overlaps,    list per tile of 4-nt overhangs at those breakpoints\n",
    "#         optimum_scores,       per-tile fidelity scores\n",
    "#         optimum_lengths,      per-tile lengths\n",
    "#         oligo_array_indices)  per-tile [start_idx, end_idx] used for length calc\n",
    "def optimize_gene(gene, \n",
    "                  max_tile_size,\n",
    "                  first_last_block_reduction,\n",
    "                  block_size_range=block_size_range, \n",
    "                  slack=slack, \n",
    "                  empirical=bsaI_empirical, \n",
    "                  overhang_blacklist=overhang_blacklist): \n",
    "    \n",
    "    #setup initial inputs to optimization\n",
    "    gene_size = len(gene)\n",
    "    protein_size = len(gene.translate())\n",
    "        \n",
    "    #exclude gene if it is too big\n",
    "    if protein_size > 1000:\n",
    "        print('Protein size too big!')\n",
    "        \n",
    "    #divide genes between 500 and 1000aa into two blocks\n",
    "    elif protein_size > 620:\n",
    "        print('Protein size too big! Will add two superblock (620aa+ proteins) soon.')\n",
    "        \n",
    "    else:\n",
    "        #gene is one superblock \n",
    "        #print('Protein is one superblock.')\n",
    "        block_size = block_size_range[0] + np.argmin(\n",
    "            [abs((gene_size+2*first_last_block_reduction)/(i+block_size_range[0]) - \\\n",
    "                     round((gene_size+2*first_last_block_reduction)/(i+block_size_range[0]))) \\\n",
    "                 for i in range(0, block_size_range[1]-block_size_range[0])])\n",
    "        \n",
    "        \n",
    "        # now, set initial breakpoints\n",
    "        fragment_number = int((gene_size+2*first_last_block_reduction)/block_size)\n",
    "        \n",
    "        # if any of the tiles are too big?\n",
    "        tile_lengths = [1000]\n",
    "        while max(tile_lengths) > (max_tile_size-2*slack):\n",
    "            fragment_number = fragment_number + 1\n",
    "            first_breakpoint = 0\n",
    "            last_breakpoint = gene_size-4\n",
    "            step = (last_breakpoint - first_breakpoint + 2*first_last_block_reduction)/fragment_number\n",
    "            evenly_spaced_floats = [first_breakpoint] + [step * i - first_last_block_reduction for i in range(1,fragment_number)] + [last_breakpoint]        \n",
    "            initial_breakpoints = [[first_breakpoint,int(evenly_spaced_floats[1])+slack+2,last_breakpoint]] + \\\n",
    "                                    [[0,int(evenly_spaced_floats[i])-2-slack,int(evenly_spaced_floats[i+1])+slack+2,last_breakpoint] for i in range(1,len(evenly_spaced_floats)-2)] + \\\n",
    "                                    [[0,int(evenly_spaced_floats[-2])-2-slack,last_breakpoint]]\n",
    "            tile_lengths = [int(evenly_spaced_floats[1])+slack+2-first_breakpoint+first_last_block_reduction+4] + \\\n",
    "                                    [int(evenly_spaced_floats[i+1])-int(evenly_spaced_floats[i])+2*(slack+2)+4 for i in range(1,len(evenly_spaced_floats)-2)] + \\\n",
    "                                    [last_breakpoint+4-int(evenly_spaced_floats[-2])+slack+2+first_last_block_reduction]\n",
    "            \n",
    "\n",
    "        #optimize each breakpoint\n",
    "        optimum_breakpoints = []\n",
    "        optimum_scores = []\n",
    "        optimum_lengths = []\n",
    "        oligo_array_indices = []\n",
    "        for k,breakpoint in enumerate(initial_breakpoints):\n",
    "            if len(breakpoint) == 3:\n",
    "                indices_of_array = [0, 1] if k==0 else [1, 2]\n",
    "                optimum_breakpoint, optimum_score, optimum_length = optimize_breakpoints(gene, breakpoint, [1], indices_of_array,\n",
    "                                                            slack, empirical=bsaI_empirical, overhang_blacklist=overhang_blacklist)\n",
    "                optimum_breakpoints.append(optimum_breakpoint)\n",
    "                optimum_scores.append(optimum_score)\n",
    "                optimum_lengths.append(optimum_length)\n",
    "                oligo_array_indices.append(indices_of_array)\n",
    "            else:\n",
    "                indices_of_array = [1, 2]\n",
    "                optimum_breakpoint, optimum_score, optimum_length = optimize_breakpoints(gene, breakpoint, [1, 2], indices_of_array,\n",
    "                                                            slack, empirical=bsaI_empirical, overhang_blacklist=overhang_blacklist)\n",
    "                optimum_breakpoints.append(optimum_breakpoint)\n",
    "                optimum_scores.append(optimum_score)\n",
    "                optimum_lengths.append(optimum_length)\n",
    "                oligo_array_indices.append(indices_of_array)\n",
    "    \n",
    "    optimum_overlaps = [[str(gene[t:(t+4)]) for t in s] for s in optimum_breakpoints]\n",
    "    if all([s >= 0.95 for s in optimum_scores]):\n",
    "        print('All regions are high fidelity!')\n",
    "    elif all([s >= 0.9 for s in optimum_scores]):\n",
    "        print('Some regions are medium fidelity.')\n",
    "    else:\n",
    "        print('Some regions are low fidelity. Look closer')\n",
    "        \n",
    "    return optimum_breakpoints, optimum_overlaps, optimum_scores, optimum_lengths, oligo_array_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13d2d248-a747-401a-b09f-06d4f5b554a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for designing primers given length and Tm restrictions\n",
    "def generate_primer(DNA_seq,\n",
    "                     Fwd=True,\n",
    "                     extendtoCG=False,\n",
    "                     smallest_primer_size=16,\n",
    "                     largest_primer_size=30,\n",
    "                     Tm=55):\n",
    "    \n",
    "    #Setup melting temperature arrays\n",
    "    melt_temp_array = np.zeros(largest_primer_size-smallest_primer_size+1)\n",
    "    \n",
    "    if Fwd:\n",
    "        DNA_seq_touse = DNA_seq\n",
    "    else:\n",
    "        DNA_seq_touse = DNA_seq.reverse_complement()\n",
    "            \n",
    "    #Make melting temperature arrays\n",
    "    primer_length = 0\n",
    "    for i in range(smallest_primer_size,largest_primer_size+1):\n",
    "        melt_temp_array[i-smallest_primer_size] = mt.Tm_NN(DNA_seq_touse[0:i])\n",
    "        \n",
    "        #Pick F primer when Tm is first >F_Tm\n",
    "        if (melt_temp_array[i-smallest_primer_size] >= Tm) & (primer_length==0):\n",
    "            primer_length = i\n",
    "    \n",
    "    #If Tm isnt high enough after max bases, just set primer length to be max and hope it works\n",
    "    if (primer_length == 0):\n",
    "        primer_length = largest_primer_size\n",
    "        \n",
    "    if extendtoCG:\n",
    "        while ((DNA_seq_touse[primer_length-1] == 'A') | (DNA_seq_touse[primer_length-1] == 'T')) & \\\n",
    "                    (primer_length < largest_primer_size):\n",
    "            primer_length += 1\n",
    "    \n",
    "    return DNA_seq_touse[0:primer_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad65952b-f49f-4faa-b7be-47a0347c7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is making the mutagenesis library for each tile. \n",
    "# Step1: makes sure the region is a multiple of 3\n",
    "# Step2: adds the wt sequence to the list\n",
    "# Step3: generate variants and return array\n",
    "def make_mutations(region_name,\n",
    "                       region,\n",
    "                       region_flanks=[Seq(''),Seq('')],\n",
    "                       nt_start=0, #zero-indexed!\n",
    "                       wt_only=False,\n",
    "                       synonymous=True,\n",
    "                       stops='TAA',\n",
    "                       all3ntdeletions=True,\n",
    "                       mutation_list=False,\n",
    "                       codons_ranked_by_usage=codons_ranked_by_usage,\n",
    "                       aa_start=0,\n",
    "                       aa_stop=None) :\n",
    "                       \n",
    "    oligo_array = {}\n",
    "    #Check that region has size divisible by three\n",
    "    if (len(region)/3 != len(region)//3) | (nt_start/3 != nt_start//3):\n",
    "        print('Region is not translatable!')\n",
    "        \n",
    "    else:\n",
    "        #add wt seq to oligo array\n",
    "        oligo_name = region_name + '_WT'\n",
    "        wt_seq = \\\n",
    "            region_flanks[0] + region + region_flanks[1]\n",
    "        oligo_array[oligo_name] = wt_seq\n",
    "        \n",
    "        if not wt_only:\n",
    "            \n",
    "            # see if a mutation list was given\n",
    "            if mutation_list == False:\n",
    "                    \n",
    "                #loop over amino acids\n",
    "                for j in range(0,len(region),3):\n",
    "\n",
    "                    #add all missense variants\n",
    "                    aa = region[j:(j+3)].translate()\n",
    "                    for aa_to in codons_ranked_by_usage.keys():\n",
    "                        if aa_to != aa:\n",
    "                            oligo_name = region_name + '_' + str(aa) + str((nt_start+j)//3+1+aa_start) + str(aa_to)\n",
    "                            seq_to_append = \\\n",
    "                                region_flanks[0] + \\\n",
    "                                region[0:j] + Seq(codons_ranked_by_usage[aa_to][0]) + \\\n",
    "                                region[(j+3):] + \\\n",
    "                                region_flanks[1]\n",
    "                            oligo_array[oligo_name] = seq_to_append\n",
    "\n",
    "                    #add synonymous variant if True and if possible, \n",
    "                    # using the most common codon that is NOT the codon in the gene\n",
    "                    if synonymous:\n",
    "                        if len(codons_ranked_by_usage[aa]) > 1:\n",
    "                            oligo_name = region_name + '_' + str(aa) + str((nt_start+j)//3+1+aa_start) + str(aa)\n",
    "                            possible_codons = codons_ranked_by_usage[aa].copy()\n",
    "                            possible_codons.remove(region[j:(j+3)])\n",
    "                            seq_to_append = \\\n",
    "                                region_flanks[0] + \\\n",
    "                                region[0:j] + Seq(possible_codons[0]) + \\\n",
    "                                region[(j+3):] + \\\n",
    "                                region_flanks[1]\n",
    "                            oligo_array[oligo_name] = seq_to_append\n",
    "\n",
    "                    #add stops if true\n",
    "                    if stops:\n",
    "                        oligo_name = region_name + '_' + str(aa) + str((nt_start+j)//3+1+aa_start) + 'X'\n",
    "                        seq_to_append = \\\n",
    "                            region_flanks[0] + \\\n",
    "                            region[0:j] + Seq(stops) + \\\n",
    "                            region[(j+3):] + \\\n",
    "                            region_flanks[1]\n",
    "                        oligo_array[oligo_name] = seq_to_append\n",
    "\n",
    "                    #add all 3nt deletions if True\n",
    "                    if all3ntdeletions:\n",
    "                        for k in range(0,3):\n",
    "                            if j+k+3 <= len(region):\n",
    "                                oligo_name = region_name + '_' + 'del' + str(nt_start+j+k+1+3*aa_start)\n",
    "                                seq_to_append = \\\n",
    "                                    region_flanks[0] + \\\n",
    "                                    region[0:(j+k)] + \\\n",
    "                                    region[(j+k+3):] + \\\n",
    "                                    region_flanks[1]\n",
    "                                oligo_array[oligo_name] = seq_to_append\n",
    "                                \n",
    "            else:\n",
    "                \n",
    "                #loop over mutation list\n",
    "                for i in range(len(mutation_list)):\n",
    "                        \n",
    "                    #iterate over every single aa change\n",
    "                    oligo_name = region_name + '_' + 'variant' + str(i+1)\n",
    "                    seq_to_append = region\n",
    "                    for k,v in enumerate(mutation_list[i]):\n",
    "                        aa_from = v[0]\n",
    "                        aa_to = v[-1]\n",
    "                        pos = int(v[1:-1])\n",
    "                        j=3*(pos-(nt_start//3+1))\n",
    "                        aa = region[j:(j+3)].translate()\n",
    "                        if aa != aa_from:\n",
    "                            print('Check mutation list!')\n",
    "                        else:\n",
    "                            seq_to_append = \\\n",
    "                                seq_to_append[0:j] + \\\n",
    "                                Seq(codons_ranked_by_usage[aa_to][0]) + \\\n",
    "                                seq_to_append[(j+3):]\n",
    "\n",
    "                    # append oligo to array\n",
    "                    seq_to_append = region_flanks[0] + \\\n",
    "                                    seq_to_append + \\\n",
    "                                    region_flanks[1]\n",
    "                    oligo_array[oligo_name] = seq_to_append\n",
    "        \n",
    "    return oligo_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bdf791-db19-463a-a75f-c21077c9c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the pipeline for combining the above functions to make the mutational scanning libraries\n",
    "# \n",
    "def write_oligo_library(genes,\n",
    "                        oligo_file='./oligo_test.csv',\n",
    "                        primer_file='./primer_test.tsv',\n",
    "                        gbl_file='./gbl_test.tsv',\n",
    "                        gbl_large_file='./gbl_test_large.tsv',\n",
    "                        amp_primer_key_file='./amp_primer_key.tsv',\n",
    "                        breakpoint_file='./breakpoints.tsv',\n",
    "                        primer_set=orthogonal_primers_touse,\n",
    "                        codons_ranked_by_usage=codons_ranked_by_usage,\n",
    "                        block_size_range=block_size_range, \n",
    "                        max_oligo_size=max_oligo_size,\n",
    "                        slack=slack, \n",
    "                        empirical=bsaI_empirical, \n",
    "                        overhang_blacklist=overhang_blacklist,\n",
    "                        validated_primer_set=False,\n",
    "                        aa_start=False,\n",
    "                        aa_stop=False,\n",
    "                        wt_only=False,\n",
    "                        synonymous=True,\n",
    "                        stops='TAA',\n",
    "                        all3ntdeletions=True,\n",
    "                        mutations_to_use=False,\n",
    "                        find_pcr_primers=True,\n",
    "                        smallest_primer_size=16,\n",
    "                        largest_primer_size=30,\n",
    "                        Tm=55,\n",
    "                        extendtoCG=True,\n",
    "                        bsaI_firstoverlap='CGTC',\n",
    "                        bsaI_lastoverlap='GCAT',\n",
    "                        all_blocks=True,\n",
    "                        blocks_to_include=False,\n",
    "                        tile_boundaries=False,\n",
    "                        paqcIcapF=True,\n",
    "                        paqcIcapR=True,\n",
    "                        check_all_primers=True,\n",
    "                        qc_melt_temp_threshold=32,\n",
    "                        gblock_min_size=300,\n",
    "                        gblock_large_threshold=1000,\n",
    "                        randomsequencepad=randomsequencepad):\n",
    "    \n",
    "    #Split up primer set into F and R primers, cannot do more than 82 sublibraries\n",
    "    oligo_primer_counter = 0\n",
    "    oligo_array = {}\n",
    "    amp_primers = {}\n",
    "    gblocks = {}\n",
    "    num_blocks = {}\n",
    "    amp_primer_dict = {}\n",
    "    breakpoint_dict = {}\n",
    "    \n",
    "    #Convert genes to Seq and genes to list\n",
    "    gene_names = list(genes.keys())\n",
    "    genes = [Seq(genes[gene_name].upper()) for gene_name in gene_names]\n",
    "    \n",
    "    #PaqCI and BsaI site sequences\n",
    "    paqcI_seq = Seq('CACCTGC')\n",
    "    paqcI_seqplusfour = Seq('GCTCTTCCTAG')\n",
    "    bsaI_seq = Seq('GGTCTC')\n",
    "    bsaI_seqplusone = Seq('GGTCTCT')\n",
    "    pcr_capseq = Seq('GGCTAC') + bsaI_seqplusone\n",
    "    gbl_capseq_F = Seq('CCGCGTGATTACGAGTCG') + pcr_capseq\n",
    "    gbl_capseq_R = Seq('GGGTTAGCAAGTGGCAGCCT') + pcr_capseq\n",
    "    \n",
    "    # set max size of a tile\n",
    "    primer_len = len(primer_set['Forward Primer'][0])\n",
    "    max_tile_size = max_oligo_size - 2*primer_len - 2*len(bsaI_seqplusone)\n",
    "    first_last_block_reduction = len(paqcI_seqplusfour)\n",
    "    \n",
    "    # iterate over genes\n",
    "    for r,gene in enumerate(genes):\n",
    "        \n",
    "        gene_name = gene_names[r]\n",
    "        print('Processing gene ' + str(r+1) + ': ' + gene_name)\n",
    "        \n",
    "        # amino acid to start at\n",
    "        if aa_start and gene_name in aa_start:\n",
    "            aa_start_gene = aa_start[gene_name] - 1\n",
    "        else:\n",
    "            aa_start_gene = 0\n",
    "\n",
    "        if aa_stop and gene_name in aa_stop:\n",
    "            aa_stop_gene = aa_stop[gene_name]\n",
    "        else:\n",
    "            aa_stop_gene = None\n",
    "        \n",
    "        #exclude if gene size is not divisible by three\n",
    "        if len(gene)/3 != len(gene)//3:\n",
    "            print('Gene length is not divisible by 3!')\n",
    "    \n",
    "        #exclude if there is a paqcI site in the gene\n",
    "        elif any([True for kmer in build_kmers(gene, len(paqcI_seq)) if kmer==paqcI_seq]) | \\\n",
    "            any([True for kmer in build_kmers(gene.reverse_complement(), len(paqcI_seq)) if kmer==paqcI_seq]):\n",
    "            print('Gene has PaqCI site!')\n",
    "        \n",
    "        #exclude if there is a BsaI site in the gene\n",
    "        elif any([True for kmer in build_kmers(gene, len(bsaI_seq)) if kmer==bsaI_seq]) | \\\n",
    "            any([True for kmer in build_kmers(gene.reverse_complement(), len(bsaI_seq)) if kmer==bsaI_seq]):\n",
    "            print('Gene has BsaI site!')\n",
    "            \n",
    "        else:\n",
    "            print('Gene has no PaqCI or BsaI sites! Performing GoldenGate optimization...')\n",
    "            \n",
    "            #cap gene with BsaI breakpoints and possible PaqCI sites \n",
    "            if paqcIcapF & paqcIcapR:\n",
    "                gene_capped = bsaI_firstoverlap + paqcI_seqplusfour + \\\n",
    "                        gene + paqcI_seqplusfour.reverse_complement() + bsaI_lastoverlap\n",
    "                capping_length_F = len(bsaI_firstoverlap + paqcI_seqplusfour)\n",
    "                capping_length_R = len(paqcI_seqplusfour.reverse_complement() + bsaI_lastoverlap)\n",
    "            elif paqcIcapF:\n",
    "                gene_capped = bsaI_firstoverlap + paqcI_seqplusfour + \\\n",
    "                        gene + bsaI_lastoverlap\n",
    "                capping_length_F = len(bsaI_firstoverlap + paqcI_seqplusfour)\n",
    "                capping_length_R = len(bsaI_lastoverlap)\n",
    "            elif paqcIcapR:\n",
    "                gene_capped = bsaI_firstoverlap + \\\n",
    "                        gene + paqcI_seqplusfour.reverse_complement() + bsaI_lastoverlap\n",
    "                capping_length_F = len(bsaI_firstoverlap)\n",
    "                capping_length_R = len(paqcI_seqplusfour.reverse_complement() + bsaI_lastoverlap)\n",
    "            else:\n",
    "                gene_capped = bsaI_firstoverlap + gene + bsaI_lastoverlap\n",
    "                capping_length_F = len(bsaI_firstoverlap)\n",
    "                capping_length_R = len(bsaI_lastoverlap)\n",
    "            \n",
    "            #Optimize gene if tile boundaries are not given\n",
    "            if tile_boundaries is False:\n",
    "                optimum_breakpoints, optimum_overlaps, optimum_scores, optimum_lengths, oligo_array_indices = \\\n",
    "                optimize_gene(gene_capped, \n",
    "                          max_tile_size=max_tile_size,\n",
    "                          first_last_block_reduction=first_last_block_reduction,\n",
    "                          block_size_range=block_size_range, \n",
    "                          slack=slack, \n",
    "                          empirical=bsaI_empirical, \n",
    "                          overhang_blacklist=overhang_blacklist)\n",
    "                pprint.pprint({'Optimum Breakpoints': optimum_breakpoints, \n",
    "                       'Optimum Overlaps': optimum_overlaps, \n",
    "                       'Optimum Scores': optimum_scores})\n",
    "                num_blocks[gene_name] = len(optimum_breakpoints)\n",
    "            else:\n",
    "                optimum_breakpoints = tile_boundaries[gene_name]\n",
    "                if len(optimum_breakpoints[0])==3:\n",
    "                    if len(optimum_breakpoints)>1:\n",
    "                        #multiple tiles, including one at beginning of gene\n",
    "                        oligo_array_indices = [[0,1]] + [[1,2]]*(len(optimum_breakpoints)-1)\n",
    "                    else:\n",
    "                        # one tile\n",
    "                        if ((optimum_breakpoints[1]-optimum_breakpoints[0]) > (optimum_breakpoints[2]-optimum_breakpoints[1])):\n",
    "                            # at end of gene\n",
    "                            oligo_array_indices = [[1,2]]\n",
    "                        else:\n",
    "                            # at beginning of gene\n",
    "                            oligo_array_indices = [[0,1]]\n",
    "                else:\n",
    "                    # multiple tiles, starting in the middle\n",
    "                    oligo_array_indices = [[1,2]]*(len(optimum_breakpoints))\n",
    "                num_blocks[gene_name] = len(optimum_breakpoints)\n",
    "                \n",
    "            \n",
    "            #add primers for gene_F and gene_R that are repeated constantly throughout the PCRs\n",
    "            #note: should probably prevalidate these primers!\n",
    "            if find_pcr_primers:\n",
    "                F_primer = generate_primer(gene,\n",
    "                                           Fwd=True,\n",
    "                                           extendtoCG=extendtoCG,\n",
    "                                           smallest_primer_size=smallest_primer_size,\n",
    "                                           largest_primer_size=largest_primer_size,\n",
    "                                           Tm=Tm)\n",
    "                F_primer = pcr_capseq + bsaI_firstoverlap + paqcI_seqplusfour + F_primer\n",
    "                amp_primers[gene_name+'_gene'+'_ampF'] = F_primer\n",
    "                R_primer = generate_primer(gene,\n",
    "                                           Fwd=False,\n",
    "                                           extendtoCG=extendtoCG,\n",
    "                                           smallest_primer_size=smallest_primer_size,\n",
    "                                           largest_primer_size=largest_primer_size,\n",
    "                                           Tm=Tm)\n",
    "                R_primer = pcr_capseq + Seq(bsaI_lastoverlap).reverse_complement() + \\\n",
    "                            paqcI_seqplusfour + R_primer\n",
    "                amp_primers[gene_name+'_gene'+'_ampR'] = R_primer\n",
    "            \n",
    "            #make oligos, primers, gblocks for each block\n",
    "            for i,breakpoint in enumerate(optimum_breakpoints):\n",
    "                \n",
    "                #find indices of breakpoint that correspond to oligo vs need to be PCRed/gblock\n",
    "                pcr_indices = [[j,j+1] for j in range(len(breakpoint)-1)]\n",
    "                pcr_indices.remove(oligo_array_indices[i])\n",
    "                \n",
    "                #find mutagenic window of oligo\n",
    "                oligo_breaks = [breakpoint[j] for j in oligo_array_indices[i]]\n",
    "                oligo_mutagenic_window = [int(3*np.ceil(max(oligo_breaks[0]+4-capping_length_F,3)/3)), int(3*np.floor(min(oligo_breaks[1]-capping_length_F,len(gene)-1)/3))]\n",
    "                \n",
    "                #subset the right block if needed\n",
    "                if (all_blocks == True) | ((i+1) in blocks_to_include[r] if blocks_to_include != False else True): #subset on allowed blocks\n",
    "                \n",
    "                    #add pcr primers and gblocks, one segment at a time\n",
    "                    for k,pcr_index in enumerate(pcr_indices):\n",
    "                        piece_name = gene_name + '_block' + str(i+1) + '_s' + str(k+1)\n",
    "                        pcr_breaks = [breakpoint[j] for j in pcr_index]\n",
    "                                            \n",
    "                        #get pcr primers\n",
    "                        if find_pcr_primers:\n",
    "                            if pcr_breaks[0] == breakpoint[0]: #Fragment beginning at gene start \n",
    "                                R_primer = generate_primer(gene_capped[pcr_breaks[0]:(pcr_breaks[1]+4)],\n",
    "                                                           Fwd=False,\n",
    "                                                           extendtoCG=extendtoCG,\n",
    "                                                           smallest_primer_size=smallest_primer_size,\n",
    "                                                           largest_primer_size=largest_primer_size,\n",
    "                                                           Tm=Tm)\n",
    "                                R_primer = pcr_capseq + R_primer\n",
    "                                amp_primers[piece_name+'_ampR'] = R_primer\n",
    "                            elif pcr_breaks[1] == breakpoint[-1]: #Fragment ending at gene end\n",
    "                                F_primer = generate_primer(gene_capped[pcr_breaks[0]:(pcr_breaks[1]+4)],\n",
    "                                                           Fwd=True,\n",
    "                                                           extendtoCG=extendtoCG,\n",
    "                                                           smallest_primer_size=smallest_primer_size,\n",
    "                                                           largest_primer_size=largest_primer_size,\n",
    "                                                           Tm=Tm)\n",
    "                                F_primer = pcr_capseq + F_primer\n",
    "                                amp_primers[piece_name+'_ampF'] = F_primer\n",
    "                            else:\n",
    "                                F_primer = generate_primer(gene_capped[pcr_breaks[0]:(pcr_breaks[1]+4)],\n",
    "                                                           Fwd=True,\n",
    "                                                           extendtoCG=extendtoCG,\n",
    "                                                           smallest_primer_size=smallest_primer_size,\n",
    "                                                           largest_primer_size=largest_primer_size,\n",
    "                                                           Tm=Tm)\n",
    "                                F_primer = pcr_capseq + F_primer\n",
    "                                R_primer = generate_primer(gene_capped[pcr_breaks[0]:(pcr_breaks[1]+4)],\n",
    "                                                           Fwd=False,\n",
    "                                                           extendtoCG=extendtoCG,\n",
    "                                                           smallest_primer_size=smallest_primer_size,\n",
    "                                                           largest_primer_size=largest_primer_size,\n",
    "                                                           Tm=Tm)\n",
    "                                R_primer = pcr_capseq + R_primer\n",
    "                                amp_primers[piece_name+'_ampF'] = F_primer\n",
    "                                amp_primers[piece_name+'_ampR'] = R_primer\n",
    "\n",
    "                        #make gblocks\n",
    "                        gbl = gbl_capseq_F + gene_capped[pcr_breaks[0]:(pcr_breaks[1]+4)] + gbl_capseq_R.reverse_complement()\n",
    "                        gblocks[piece_name] = gbl\n",
    "                        \n",
    "                    #add oligos to oligo array, checking first for validated primers if they are given\n",
    "                    validated=False\n",
    "                    if validated_primer_set is not False:\n",
    "                        validated_combo = validated_primer_set.query('Gene == @gene_name & Block == (@i+1)')\n",
    "                        if not validated_combo.empty:\n",
    "                            validated=True\n",
    "                            name_primer_F, primer_F, name_primer_R, primer_R = \\\n",
    "                                validated_combo[['Forward Name',\n",
    "                                                  'Forward Primer',\n",
    "                                                  'Reverse Name',\n",
    "                                                  'Reverse Primer']].values[0]\n",
    "                        else:\n",
    "                            name_primer_F, primer_F, name_primer_R, primer_R = \\\n",
    "                                primer_set.iloc[oligo_primer_counter,][['Forward Name',\n",
    "                                                                      'Forward Primer',\n",
    "                                                                      'Reverse Name',\n",
    "                                                                      'Reverse Primer']]\n",
    "                            oligo_primer_counter += 1\n",
    "                    else:\n",
    "                        name_primer_F, primer_F, name_primer_R, primer_R = \\\n",
    "                                primer_set.iloc[oligo_primer_counter,][['Forward Name',\n",
    "                                                                      'Forward Primer',\n",
    "                                                                      'Reverse Name',\n",
    "                                                                      'Reverse Primer']]\n",
    "                        oligo_primer_counter += 1\n",
    "                        \n",
    "                    # if mutations are given, use those - otherwise make all mutations or wtonly\n",
    "                    if mutations_to_use == False:\n",
    "                        add_on_array = make_mutations(gene_name + '_block' + str(i+1),\n",
    "                                           gene[oligo_mutagenic_window[0]:oligo_mutagenic_window[1]],\n",
    "                                           region_flanks=[Seq(primer_F) + \\\n",
    "                                                          bsaI_seqplusone + \\\n",
    "                                                          gene_capped[oligo_breaks[0]:(oligo_mutagenic_window[0]+capping_length_F)] ,\n",
    "                                                          gene_capped[(oligo_mutagenic_window[1]+capping_length_F):(oligo_breaks[1]+4)] + \\\n",
    "                                                          bsaI_seqplusone.reverse_complement() + \\\n",
    "                                                          Seq(primer_R).reverse_complement()],\n",
    "                                           nt_start=oligo_mutagenic_window[0],\n",
    "                                           wt_only=wt_only,\n",
    "                                           synonymous=synonymous,\n",
    "                                           stops=stops,\n",
    "                                           all3ntdeletions=all3ntdeletions,\n",
    "                                           codons_ranked_by_usage=codons_ranked_by_usage,\n",
    "                                           aa_start=aa_start_gene)\n",
    "                    else:\n",
    "                        add_on_array = make_mutations(gene_name + '_block' + str(i+1),\n",
    "                                           gene[oligo_mutagenic_window[0]:oligo_mutagenic_window[1]],\n",
    "                                           region_flanks=[Seq(primer_F) + \\\n",
    "                                                          bsaI_seqplusone + \\\n",
    "                                                          gene_capped[oligo_breaks[0]:(oligo_mutagenic_window[0]+capping_length_F)] ,\n",
    "                                                          gene_capped[(oligo_mutagenic_window[1]+capping_length_F):(oligo_breaks[1]+4)] + \\\n",
    "                                                          bsaI_seqplusone.reverse_complement() + \\\n",
    "                                                          Seq(primer_R).reverse_complement()],\n",
    "                                           nt_start=oligo_mutagenic_window[0],\n",
    "                                           mutation_list=mutations_to_use[(gene_name,i+1)],\n",
    "                                           codons_ranked_by_usage=codons_ranked_by_usage,\n",
    "                                           aa_start=aa_start_gene,\n",
    "                                           aa_stop=aa_stop_gene)\n",
    "                    oligo_array.update(add_on_array)\n",
    "                    amp_primer_dict.update({(gene_name,i+1): (name_primer_F,primer_F,name_primer_R,primer_R,validated)})\n",
    "                    breakpoint_dict.update({(gene_name,i+1): oligo_mutagenic_window})\n",
    "                    \n",
    "    #Check that max oligo is less than the max oligo length\n",
    "    if sum([len(s)>max_oligo_size for s in oligo_array.values()]) == 0:\n",
    "        print('All oligos are below the maximum 250bp!')\n",
    "    else:\n",
    "        print('Some oligos are TOO BIG!')\n",
    "        \n",
    "    #Check for nonspecific amplification\n",
    "    wt_oligos = {tuple([key.split('_')[0],\n",
    "                        int((key.split('_block')[1]).split('_')[0])]\n",
    "                      ):oligo_array[key] \\\n",
    "                     for key in oligo_array.keys() if 'WT' in key}\n",
    "    nonspecific_primers = post_qc(amp_primer_dict, \n",
    "                                  wt_oligos,\n",
    "                                  primer_set, \n",
    "                                  melt_temp_threshold=qc_melt_temp_threshold,\n",
    "                                  check_all_primers=check_all_primers)\n",
    "    \n",
    "    # Check that all mutagenic windows overlap\n",
    "    breakpoint_df = pd.DataFrame.from_dict(breakpoint_dict, orient='index', columns=['Mutagenesis Start','Mutagenesis End'])\n",
    "    breakpoint_df.index = pd.MultiIndex.from_tuples(breakpoint_dict.keys())\n",
    "    breakpoint_df = breakpoint_df.reset_index().rename(columns={'level_0':'Gene',\n",
    "                                                                'level_1':'Block'})\n",
    "    if (mutations_to_use == False) and (all_blocks == True):\n",
    "        missed_counter = 0\n",
    "        for r,gene_group_breakpoints in breakpoint_df.groupby('Gene'):\n",
    "            for k,row in gene_group_breakpoints.iterrows():\n",
    "                # look at whether the current row start is later than the last row end\n",
    "                if row['Block'] > 1:\n",
    "                    if row['Mutagenesis Start'] > end:\n",
    "                        missed_counter += 1\n",
    "                        print('Mutagenic window missed at ' + str(r) + ' block ' + str(row['Block']))\n",
    "                start,end = row['Mutagenesis Start'],row['Mutagenesis End']\n",
    "        if missed_counter == 0:\n",
    "            print('All mutagenic windows overlap!')\n",
    "        else:\n",
    "            print(str(missed_counter) + ' number of times the mutagenic window does not close!')\n",
    "                \n",
    "    #Remove any oligos with additional BsaI sites or PaqCI sites\n",
    "    bad_oligos = []\n",
    "    for name,oligo in oligo_array.items():\n",
    "        #check for PaqCI sites\n",
    "        paqcI_F = sum([True for kmer in build_kmers(oligo, len(paqcI_seq)) if kmer==paqcI_seq])\n",
    "        paqcI_R = sum([True for kmer in build_kmers(oligo.reverse_complement(), len(paqcI_seq)) if kmer==paqcI_seq])\n",
    "        #check that oligo is block 1 if it contains a paqcI site in the forward orientation \n",
    "        if paqcI_F > 0:\n",
    "            if ('block1' not in name) | (paqcI_F > 1):\n",
    "                bad_oligos.append(name)\n",
    "        #check that the oligo is block final if it contains a paqcI site in the reverse orientation\n",
    "        if paqcI_R > 0:\n",
    "            if ('block'+str(num_blocks[name.split('_')[0]]) not in name) | (paqcI_R > 1):\n",
    "                bad_oligos.append(name)\n",
    "        #check for more than one BsaI site\n",
    "        bsaI_F = sum([True for kmer in build_kmers(oligo, len(bsaI_seq)) if kmer==bsaI_seq])\n",
    "        bsaI_R = sum([True for kmer in build_kmers(oligo.reverse_complement(), len(bsaI_seq)) if kmer==bsaI_seq])\n",
    "        if (bsaI_F != 1) | (bsaI_R != 1):\n",
    "            bad_oligos.append(name)\n",
    "    bad_oligos=np.unique(bad_oligos)\n",
    "    for oligo_name in bad_oligos:\n",
    "        del oligo_array[oligo_name]\n",
    "    print(str(len(bad_oligos)) + ' oligos deleted due to errant restriction sites.')\n",
    "    \n",
    "    #Remove any duplicate oligos\n",
    "    new_dict = {}\n",
    "    seen_values = set()\n",
    "    counter=0\n",
    "    for key, value in oligo_array.items():\n",
    "        if value not in seen_values:\n",
    "            new_dict[key] = value\n",
    "            seen_values.add(value)\n",
    "        else:\n",
    "            counter += 1\n",
    "    print(str(counter) + ' oligos removed due to duplication.')\n",
    "    oligo_array = new_dict\n",
    "    del new_dict\n",
    "    \n",
    "    #write oligo array to file\n",
    "    with open(oligo_file, 'w') as f:\n",
    "        for key in oligo_array.keys():\n",
    "            f.write(\"%s,%s\\n\"%(key,oligo_array[key]))\n",
    "    f.close()\n",
    "            \n",
    "    #write primers to file\n",
    "    if find_pcr_primers:\n",
    "        primer_order_sheet = []\n",
    "        for key in amp_primers.keys():\n",
    "            primer_order_sheet.append(key + '\\t' + \\\n",
    "                     str(amp_primers[key]) + \\\n",
    "                     '\\t' + '25nm' + '\\t' + 'STD\\n')\n",
    "        print(*primer_order_sheet)\n",
    "        with open(primer_file, 'w') as f:\n",
    "            for line in primer_order_sheet:\n",
    "                f.write(line)\n",
    "        f.close()\n",
    "    \n",
    "    #write amplification primer key to file\n",
    "    amp_primer_key = ['Gene' + '\\t' + 'Block' + '\\t' + \\\n",
    "                      'Forward Primer Well' + '\\t' + 'Forward Primer' + '\\t' + \\\n",
    "                      'Reverse Primer Well' + '\\t' + 'Reverse Primer' + '\\t' + 'Validated' + '\\n']\n",
    "    for key in amp_primer_dict.keys():\n",
    "        genename, geneblock = key[0], str(key[1])\n",
    "        name_primer_F, primer_F, name_primer_R, primer_R, validated = amp_primer_dict[key]\n",
    "        amp_primer_key.append(genename + '\\t' + geneblock + '\\t' + \\\n",
    "                 name_primer_F + '\\t' + primer_F + '\\t' + \\\n",
    "                 name_primer_R + '\\t' + primer_R + '\\t' + str(validated) + '\\n')\n",
    "    print(*amp_primer_key)\n",
    "    with open(amp_primer_key_file, 'w') as f:\n",
    "        for line in amp_primer_key:\n",
    "            f.write(line)\n",
    "    f.close()\n",
    "    \n",
    "    #write breakpoint dict to file\n",
    "    breakpoint_df.to_csv(breakpoint_file, sep='\\t')\n",
    "    \n",
    "    #write gblocks to file\n",
    "    gblock_order_sheet = []\n",
    "    gblock_large_order_sheet = []\n",
    "    for key in gblocks.keys():\n",
    "        # pad gblock if it is not 300bp for Twist\n",
    "        if len(gblocks[key]) < gblock_min_size:\n",
    "            gblocks[key] = Seq(randomsequencepad[0:(gblock_min_size-len(gblocks[key]))]) + gblocks[key]\n",
    "        if len(gblocks[key]) < gblock_large_threshold:\n",
    "            gblock_order_sheet.append(key + '\\t' + \\\n",
    "                     str(gblocks[key]) + '\\n')\n",
    "        else:\n",
    "            gblock_large_order_sheet.append(key + '\\t' + \\\n",
    "                     str(gblocks[key]) + '\\n')\n",
    "    print(*gblock_order_sheet)\n",
    "    print(*gblock_large_order_sheet)\n",
    "    with open(gbl_file, 'w') as f:\n",
    "        for line in gblock_order_sheet:\n",
    "            f.write(line)\n",
    "    f.close()\n",
    "    with open(gbl_large_file, 'w') as f:\n",
    "        for line in gblock_large_order_sheet:\n",
    "            f.write(line)\n",
    "    f.close()\n",
    "    \n",
    "    return oligo_array,amp_primers,gblocks,amp_primer_dict,breakpoint_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
